import os
import chromadb
import pandas as pd
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client_llm = OpenAI()
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
client_db = chromadb.PersistentClient(path="./financial_rag_db")
collection = client_db.get_collection(name="card_member_data")

qrels_df = pd.read_csv("qrels.csv")
qrels_dict = {q_id: qrels_df[qrels_df['query_id'] == q_id]['doc_id'].astype(str).tolist() for q_id in qrels_df['query_id'].unique()}

queries_info = [
    {
        "q_id": "q1", 
        "text": "ì„œìš¸ì— ê±°ì£¼í•˜ëŠ” 40ëŒ€ ê³ ê° ì¤‘ êµìœ¡ë¹„ë‚˜ í•™ì› ê´€ë ¨ ì§€ì¶œì´ ë‘ë“œëŸ¬ì§€ëŠ” í•™ë¶€ëª¨ë¥¼ ì°¾ì•„ì¤˜.",
        "where": {"$and": [{"SIDO": "ì„œìš¸"}, {"AGE": {"$gte": 40}}, {"AGE": {"$lt": 50}}]},
        "llm_prompt": "ì´ ê³ ê°ì˜ ìš”ì•½ ë°ì´í„°ì— 'í•™ì›', 'ì„œì ', 'êµìœ¡'ê³¼ ê´€ë ¨ëœ ì§€ì¶œì´ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ YES. 'ìœ í†µ'ì´ë‚˜ 'ìš”ì‹ì—…'ë§Œ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ NOë¡œ ë‹µí•´."
    },
    {
        "q_id": "q2", 
        "text": "ê²½ê¸°ì— ê±°ì£¼í•˜ëŠ” 50ëŒ€ ê³ ê° ì¤‘ ìë™ì°¨ë‚˜ ì£¼ìœ  ê´€ë ¨ ì†Œë¹„ê°€ ë§ì€ ì‚¬ëŒì„ ì°¾ì•„ì¤˜.",
        "where": {"$and": [{"SIDO": "ê²½ê¸°"}, {"AGE": {"$gte": 50}}, {"AGE": {"$lt": 60}}]},
        "llm_prompt": "ì´ ê³ ê°ì˜ ìš”ì•½ ë°ì´í„°ì— 'ìë™ì°¨', 'ì—°ë£Œ', 'ì •ë¹„', 'ì£¼ìœ ' ê´€ë ¨ ì§€ì¶œì´ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©´ YES. ê·¸ ì™¸ì—ëŠ” NOë¡œ ë‹µí•´."
    }
]

# ğŸ’¡ í‰ê°€ ì§€í‘œ ê³„ì‚° ì „ìš© í•¨ìˆ˜ (Precision, Recall, F1 Score)
def calc_metrics(hits, retrieved_count, true_total):
    precision = (hits / retrieved_count) if retrieved_count > 0 else 0.0
    recall = (hits / true_total) if true_total > 0 else 0.0
    
    if precision + recall > 0:
        f1 = 2 * (precision * recall) / (precision + recall)
    else:
        f1 = 0.0
        
    return precision * 100, recall * 100, f1 * 100

def evaluate_pipeline():
    results_list = []
    retrieve_k = 50  # 20ëª… ê²€ìƒ‰

    for info in queries_info:
        q_id = info["q_id"]
        true_answers = qrels_dict.get(q_id, [])
        total_true = len(true_answers)  # ì •ë‹µì§€ì— ìˆëŠ” ì§„ì§œ ì •ë‹µì˜ ì´ ê°œìˆ˜
        
        query_embedding = model.encode(info["text"]).tolist()

        # Step 0: ë¬´ì§€ì„± ë²¡í„° ê²€ìƒ‰
        res_0 = collection.query(query_embeddings=[query_embedding], n_results=retrieve_k)
        hits_0 = sum(1 for doc in res_0['ids'][0] if doc in true_answers)
        p0, r0, f1_0 = calc_metrics(hits_0, retrieve_k, total_true)

        # Step 1: SQL + ë²¡í„° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        res_1 = collection.query(query_embeddings=[query_embedding], n_results=retrieve_k, where=info["where"])
        hits_1 = sum(1 for doc in res_1['ids'][0] if doc in true_answers)
        p1, r1, f1_1 = calc_metrics(hits_1, retrieve_k, total_true)

        # Step 2: LLM ì˜ë„ í•„í„°ë§
        hits_2 = 0
        passed_ids_2 = []
        for i, doc_id in enumerate(res_1['ids'][0]):
            summary = res_1['documents'][0][i]
            response = client_llm.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": f"ì¡°ê±´: {info['llm_prompt']}\në°ì´í„°: {summary}\nYES/NOë§Œ ë‹µí•´."}],
                temperature=0.0
            )
            if response.choices[0].message.content.strip().startswith("YES"):
                passed_ids_2.append(doc_id)
                if doc_id in true_answers: hits_2 += 1
                
        p2, r2, f1_2 = calc_metrics(hits_2, len(passed_ids_2), total_true)

        # ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        results_list.append({
            "Q": q_id.upper(),
            "Step 0 (ë‹¨ìˆœê²€ìƒ‰)": f"F1: {f1_0:.1f} (P:{p0:.1f}, R:{r0:.1f})",
            "Step 1 (SQLí•„í„°)": f"F1: {f1_1:.1f} (P:{p1:.1f}, R:{r1:.1f})",
            "Step 2 (LLMí•„í„°)": f"F1: {f1_2:.1f} (P:{p2:.1f}, R:{r2:.1f})"
        })

    return pd.DataFrame(results_list)

print("\n" + "="*80)
print("ğŸš€ [ìµœì¢… í‰ê°€ ê²°ê³¼] P=ì •ë°€ë„(Precision), R=ì¬í˜„ìœ¨(Recall), F1=ì¡°í™”í‰ê· ")
print("="*80)
print(evaluate_pipeline().to_string(index=False))