import os
import chromadb
import pandas as pd
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

# 1. .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv() 

# í‚¤ê°€ ì œëŒ€ë¡œ ë“¤ì–´ì™”ëŠ”ì§€ ì²´í¬
if not os.environ.get("OPENAI_API_KEY"):
    raise ValueError("ğŸš¨ OPENAI_API_KEYê°€ ì„¸íŒ…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”!")

client_llm = OpenAI()

# 2. ì„ë² ë”© ëª¨ë¸ ë° DB ë¡œë“œ
print("ëª¨ë¸ ë° DB ë¡œë”© ì¤‘...")
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
client_db = chromadb.PersistentClient(path="./financial_rag_db")
collection = client_db.get_collection(name="card_member_data")

# 3. ì‹¤í—˜í•  ì§ˆë¬¸ ì„¸íŒ… (ì¸ì²œ ì—¬í–‰ê°)
query_text = "ì¸ì²œì— ê±°ì£¼í•˜ëŠ” ì Šì€ ê³ ê° ì¤‘ ìˆ™ë°•Â·ì—¬í–‰ ê´€ë ¨ ì†Œë¹„ê°€ ëˆˆì— ë„ëŠ” ì‚¬ëŒì„ ì°¾ì•„ì¤˜."
where_condition = {"$and": [{"SIDO": "ì¸ì²œ"}, {"AGE": {"$lte": 39}}]}

# 4. 1ì°¨ ê²€ìƒ‰ (Step 1ê³¼ ë™ì¼)
print("\nğŸ” [1ì°¨] ë²¡í„° + SQL ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
query_embedding = model.encode(query_text).tolist()
results = collection.query(
    query_embeddings=[query_embedding],
    n_results=10,
    where=where_condition
)

# 5. 2ì°¨ ê²€ìƒ‰: LLM ê¸°ë°˜ ì˜ë„ í•„í„°ë§
print("\n[2ì°¨] LLM ì˜ë„ ê²€ì¦ ì‹œì‘ (10ëª… ëŒ€ìƒ)...\n")
final_passed_data = []

for i in range(len(results['ids'][0])):
    doc_id = results['ids'][0][i]
    summary = results['documents'][0][i]
    
    prompt = f"""
    ë‹¹ì‹ ì€ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” "ìˆ™ë°• ë° ì—¬í–‰ ê´€ë ¨ ì†Œë¹„ê°€ ëˆˆì— ë„ëŠ” ê³ ê°"ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.
    ì•„ë˜ ê³ ê°ì˜ ì†Œë¹„ ìš”ì•½ ë°ì´í„°ë¥¼ ì½ê³ , ì´ ê³ ê°ì´ ì—¬í–‰/ìˆ™ë°•(HOTEL, TRVL ë“±)ì— ìœ ì˜ë¯¸í•œ ì§€ì¶œì„ í•˜ëŠ” í˜ë¥´ì†Œë‚˜ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
    
    [ê³ ê° ë°ì´í„°]: {summary}
    
    ë‹µë³€ ê·œì¹™:
    1. ì¡°ê±´ì— ë¶€í•©í•˜ë©´ ì²« ì¤„ì— 'YES', ì•„ë‹ˆë©´ 'NO'ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    2. ë‘ ë²ˆì§¸ ì¤„ì—ëŠ” ê·¸ë ‡ê²Œ íŒë‹¨í•œ ì´ìœ ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    """
    
    response = client_llm.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.1
    )
    
    llm_answer = response.choices[0].message.content.strip()
    decision = "YES" if llm_answer.startswith("YES") else "NO"
    reason = llm_answer.split('\n')[1] if '\n' in llm_answer else llm_answer
    
    print(f"[{doc_id}] LLM íŒë‹¨: {decision} | ì´ìœ : {reason}")
    
    if decision == "YES":
        final_passed_data.append({
            "ê³ ê°ID": doc_id,
            "ë°ì´í„° ìš”ì•½": summary,
            "LLM í†µê³¼ ì—¬ë¶€": decision,
            "íŒë‹¨ ê·¼ê±°": reason
        })

# 6. ìµœì¢… ê²°ê³¼ ì¶œë ¥
print(f"\n{'='*70}")
print(f"[ìµœì¢… ê²°ê³¼] 1ì°¨ í•„í„°ë§ 10ëª… ì¤‘, LLM ê²€ì¦ì„ í†µê³¼í•œ {len(final_passed_data)}ëª…")
print(f"{'='*70}")
if final_passed_data:
    df_final = pd.DataFrame(final_passed_data)
    print(df_final.to_string(index=False))
else:
    print("ì¡°ê±´ì— ì™„ë²½íˆ ë¶€í•©í•˜ëŠ” ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤.")